{
  "metadata": {
    "name": "Examples",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "In the first paragraph, edit the line which reads\n\n ```python\nBROKERS \u003d \"\u003c\u003c BROKER STRING GOES HERE \u003e\u003e\"\n ``` \n \n and add in your Managed Streaming for Apache Kafka Bootstrap Brokers String.\n\nIt should look something like this:\n\n\n```python\nBROKERS \u003d \"b-2.my-cluster:9092,b-3.my-cluster:9092,b-1.my-cluster:9092\"\n```\n\n### Do not copy and paste this into your notebook, it will not work because this is not your bootstrap brokers connection string\n\nFrom here, we will execute this paragraph either by clicking the Play button at the top right of the paragraph, or simply by typing \u003ckbd\u003eSHIFT\u003c/kbd\u003e + \u003ckbd\u003eENTER\u003c/kbd\u003e keys with the paragraph selected.\n\n### The first paragraph execution in your notebook may take some time (30 seconds to 1 minute) to begin execution. This is to be expected. If your paragraph takes longer than 5 minutes to show results, there is an issue. Please force stop and restart the Kinesis Data Analytics application and try again\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ipyflink\n\n# install python dependencies\n%pip install confluent_kafka\n\n# KAFKA \nBROKERS \u003d \"\u003c\u003cBROKER STRING GOES HERE\u003e\u003e\"\n\nz.put(\"brokers\", BROKERS)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate, interpolate\u003dtrue)\n\nDROP TABLE IF EXISTS statefun_egress;\n\nCREATE TABLE statefun_egress (\n  `event_time` TIMESTAMP(3) METADATA FROM \u0027timestamp\u0027,\n  `partition` BIGINT METADATA VIRTUAL,\n  `offset` BIGINT METADATA VIRTUAL,\n  `message` STRING\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027greeter-egress\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027{brokers}\u0027,\n  \u0027properties.group.id\u0027 \u003d \u0027myGroup\u0027,\n  \u0027scan.startup.mode\u0027 \u003d \u0027earliest-offset\u0027,\n  \u0027format\u0027 \u003d \u0027raw\u0027\n);\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ipyflink\n\nfrom confluent_kafka import Producer\n\nuser_id \u003d \u0027Bob\u0027\npayload \u003d \u0027{\"name\": \"Bob\"}\u0027\n\np \u003d Producer({\u0027bootstrap.servers\u0027: BROKERS})\np.produce(\n    topic\u003d\u0027greeter-ingress\u0027,\n    key\u003duser_id.encode(\u0027utf-8\u0027),\n    value\u003dpayload\n)\n\np.flush()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\n\nselect * from statefun_egress;"
    }
  ]
}